{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgathai/dsc-data-serialization-lab/blob/master/dspt_phase_4_Big_data_and_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Big Data and Spark\n",
        "\n",
        "**Overview of the lecture**\n",
        "\n",
        "1. Overview of big data\n",
        "2. Intro to Spark\n",
        "3. ML with PySpark"
      ],
      "metadata": {
        "id": "INO5DZO5PmE1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nXJPtbrgPX1N"
      },
      "outputs": [],
      "source": [
        "# @title # What is big data?\n",
        "# Big Data refers to extremely large data sets that are beyond the capability of\n",
        "# traditional databases and data processing tools to capture, manage, and analyze\n",
        "# within a tolerable elapsed time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Vs in Big Data\n",
        "\n",
        "![link text](https://i1.wp.com/techvidvan.com/tutorials/wp-content/uploads/sites/2/2021/05/5-Vs-of-big-data.jpg)"
      ],
      "metadata": {
        "id": "zg_QtV1AS48U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "QCTkCKQhR69n"
      },
      "source": [
        "## Hadoop Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "RzR_D-aOR69o"
      },
      "source": [
        "![](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "rT72vahpR69o"
      },
      "source": [
        "> Considered \"old-school\"\n",
        ">\n",
        "> Slower since it has to write to disk each time\n",
        "\n",
        "- Data Processing (MapReduce)\n",
        "- Resource Management"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to Apache"
      ],
      "metadata": {
        "id": "vH6TR5bMUnYU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "MKWELwITR69o"
      },
      "source": [
        "## Apache Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "2B_lOniJR69o"
      },
      "source": [
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/1200px-Apache_Spark_logo.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "YYtz_xBYR69o"
      },
      "source": [
        "> Holds data in memory whenever possible (faster)\n",
        ">\n",
        "> Can still be built on top of Hadoop but also S3 on AWS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ydIuXzn7R69o"
      },
      "source": [
        "Spark has become king of data since it does a good job with ETL (Extract-Transform-Load) & ML in distributed systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "HtRD5i-0R69o"
      },
      "source": [
        "##### _Aside: More Detail on Spark_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "5Mud8FKRR69p"
      },
      "source": [
        "**Some Resources**\n",
        "\n",
        ">[Here](https://towardsdatascience.com/a-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427) is a great walkthrough of Spark basics!\n",
        ">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "0wg-F51QR69p"
      },
      "source": [
        "Spark is a tool for the management of big data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "L64IQs7dR69p"
      },
      "source": [
        "The origin story of Spark starts with [MapReduce](https://en.wikipedia.org/wiki/MapReduce), whose programs comprise (unsurprisingly) a \"map\" routine (for filtering and sorting) and a \"reduce\" routine (for performing some aggregate operation).\n",
        "\n",
        "Let's look at an [example](https://en.wikipedia.org/wiki/MapReduce#Logical_view):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "FqLYHmlBR69p"
      },
      "source": [
        "\n",
        "\n",
        "Spark's advances over Hadoop MapReduce:\n",
        "\n",
        "- data processing in memory rather than on disks\n",
        "- a single framework for machine learning, graph analysis, and processing of streaming data (pp. 159-160)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Core concepts"
      ],
      "metadata": {
        "id": "AA3-cQDhV9Gr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "S3OJXdL1R69q"
      },
      "source": [
        "## RDDs:\n",
        "\n",
        "**Resilient Distributed Datasets (RDDs):** RDD is the foundational data structure of Spark, representing an immutable, distributed collection of objects that can be processed in parallel. They provide fault tolerance through lineage information.\n",
        "\n",
        "Fault tolerance achieved by keeping a record of the RDD's lineage. There are *redundancies* in the data records, so that, in the event of node failure, the other nodes can provide for data recovery. This is what makes these RDDs *resilient*.\n",
        "\n",
        " \"lineage\" refers to the sequence of transformations applied to the Resilient Distributed Dataset (RDD) data structure. It represents a way to rebuild any lost data partition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "ZsbDkeZGR694"
      },
      "source": [
        "# MapReduce\n",
        "\n",
        "MapReduce is a programming paradigm in the context of big data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "_rR_PTRHR695"
      },
      "source": [
        "1. Map: It takes input pairs and produces a set of intermediate key/value pairs.  \n",
        "2. Reduce: It accepts an intermediate key and a set of values for that key and merges these values to produce a smaller set of values.\n",
        "\n",
        "![link text](https://phoenixnap.com/kb/wp-content/uploads/2021/04/map-reduce-diagram.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "XMxVTJlER696"
      },
      "source": [
        "## Steps in MapReduce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "66EBwludR696"
      },
      "source": [
        "### Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "D7iieTkJR696"
      },
      "source": [
        "> Assign tasks to each worker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "W8SYkAh0R697"
      },
      "source": [
        "### Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "3clQ8i5FR697"
      },
      "source": [
        "> Map is another word for function: takes in data as one form, and\n",
        "transforms/maps it to another form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "sk0VL181R697"
      },
      "source": [
        "We create key-value pairs (tuples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "DRRSzLktR697"
      },
      "source": [
        "### Shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "6gL1NPvjR698"
      },
      "source": [
        "> Reorganize to make reducing easier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "7qeUj0QIR698"
      },
      "source": [
        "### Reduce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "NKEWh9UFR698"
      },
      "source": [
        "> Takes data from the map and _combines_ the data into smaller sets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML with PySpark"
      ],
      "metadata": {
        "id": "P_lA70Xyi7RQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "5c378d7f-7259-4e33-bbaf-7627af7cbb7a",
          "showTitle": false,
          "title": ""
        },
        "id": "6w3SiFwufDog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06433879-f9b7-41bc-a82a-e5cbed54f36d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285397 sha256=d79a1f3887cfdb86b314847bed6b935fab27dc9002165658653975d91c4ac961\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 120500 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u382-ga-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u382-ga-1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u382-ga-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u382-ga-1~22.04.1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u382-ga-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u382-ga-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.5.0-py3-none-any.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.6)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow)\n",
            "  Downloading databricks-cli-0.17.7.tar.gz (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow)\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2022.7.1)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.27.1)\n",
            "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.1)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/lib/python3/dist-packages (from mlflow) (4.6.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.11.2-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<7,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.22.4)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.10.1)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.19)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: pyarrow<13,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (9.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.4.4)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Collecting gunicorn<21 (from mlflow)\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.2)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.7.1)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.26.16)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow) (1.6.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow) (2.3.6)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.10/dist-packages (from gunicorn<21->mlflow) (67.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: databricks-cli\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.7-py3-none-any.whl size=143861 sha256=3f953b3a3db9c088dc81b81f141657e6eb591b09de85d9765f2e48df7c49ce7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/63/93/5402c1a09c1868a59d0b05013484e07af97a9d7b3dbd5bd39a\n",
            "Successfully built databricks-cli\n",
            "Installing collected packages: smmap, querystring-parser, Mako, gunicorn, gitdb, docker, databricks-cli, alembic, gitpython, mlflow\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.2 databricks-cli-0.17.7 docker-6.1.3 gitdb-4.0.10 gitpython-3.1.32 gunicorn-20.1.0 mlflow-2.5.0 querystring-parser-1.2.4 smmap-5.0.0\n"
          ]
        }
      ],
      "source": [
        "# Run for Google Colab environment\n",
        "!pip install pyspark\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "c7b5bd71-ac04-4b84-9a90-2e2a3b9d3670",
          "showTitle": false,
          "title": ""
        },
        "id": "h45MciAefDoi"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml import feature\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnv9oH_CfDok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4ccb47-bd42-4811-e94b-299d5c97d8a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-07 15:13:11--  https://github.com/flatiron-school/ds-spark/releases/download/v1.0/US_births_2000-2014_SSA.csv\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/379727666/12461180-d431-11eb-8163-e15e52afc9a9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230807%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230807T151311Z&X-Amz-Expires=300&X-Amz-Signature=6d7bc2dc9b9d42a8275596258791815b0da842a134c957e26b8ecab8883663cb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=379727666&response-content-disposition=attachment%3B%20filename%3DUS_births_2000-2014_SSA.csv&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-08-07 15:13:11--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/379727666/12461180-d431-11eb-8163-e15e52afc9a9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230807%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230807T151311Z&X-Amz-Expires=300&X-Amz-Signature=6d7bc2dc9b9d42a8275596258791815b0da842a134c957e26b8ecab8883663cb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=379727666&response-content-disposition=attachment%3B%20filename%3DUS_births_2000-2014_SSA.csv&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 96748 (94K) [application/octet-stream]\n",
            "Saving to: ‘US_births_2000-2014_SSA.csv’\n",
            "\n",
            "US_births_2000-2014 100%[===================>]  94.48K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-08-07 15:13:12 (9.34 MB/s) - ‘US_births_2000-2014_SSA.csv’ saved [96748/96748]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get data directly from repo\n",
        "!wget https://github.com/flatiron-school/ds-spark/releases/download/v1.0/US_births_2000-2014_SSA.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "WtbAK2P2fDom"
      },
      "source": [
        "# Set Up Spark Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "c7b5bd71-ac04-4b84-9a90-2e2a3b9d3670",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "sCQE3HabfDon"
      },
      "outputs": [],
      "source": [
        "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "_4Ml4M_ifDon"
      },
      "source": [
        "# Loading and Preprocessing the Example Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "af6b675c-1cb3-4b11-9882-1d7ba0b48d47",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "VnjgH2jifDoo"
      },
      "source": [
        "This example assumes that we have a holdout validation dataset somewhere else, so we don't need to perform a train-test split, we only need to perform cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "a7ff68e5-303d-4c4d-92c2-7a011fb94797",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "scrolled": true,
        "id": "gRfRuAO7fDop"
      },
      "outputs": [],
      "source": [
        "# Load the file since we downloaded it earlie\n",
        "df = spark.read.format('csv').option('header', 'true').\\\n",
        "load('US_births_2000-2014_SSA.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "f6263aeb-3b11-42af-a198-a568bcee1aeb",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "gD08Is_xfDop",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "d8349b90-b5e8-4788-c78a-61e5d7dbccba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year  month  date_of_month  day_of_week  births\n",
              "0  2000      1              1            6    9083\n",
              "1  2000      1              2            7    8006\n",
              "2  2000      1              3            1   11363"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-9abd761f-6f89-4628-85dc-a3b2155ee12e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date_of_month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>births</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>9083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>8006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>11363</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9abd761f-6f89-4628-85dc-a3b2155ee12e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-2e5a2753-b4a5-4f49-9c45-15b710478bbf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e5a2753-b4a5-4f49-9c45-15b710478bbf')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-2e5a2753-b4a5-4f49-9c45-15b710478bbf button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9abd761f-6f89-4628-85dc-a3b2155ee12e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9abd761f-6f89-4628-85dc-a3b2155ee12e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df.toPandas().head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "Aa4nyZjpfDok"
      },
      "source": [
        "# Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ziKb-7RvfDol"
      },
      "source": [
        "- Use `pyspark` to build machine learning models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHN7qW6X9ReM",
        "outputId": "c52dd4cd-5821-4116-c67f-70a5583dd5ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "QoRWGnpvfDop"
      },
      "source": [
        "## Process the Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "359de235-b355-4864-a9db-e11099b59f69",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "F5R4G8P0fDoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc8276e1-d630-4fa8-dee5-ef1b32950467"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('year', 'int'),\n",
              " ('month', 'int'),\n",
              " ('date_of_month', 'int'),\n",
              " ('day_of_week', 'int'),\n",
              " ('births', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "d39ba897-3457-4e14-b998-f25b26c409da",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "_C3sPrWbfDoq"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn('births', df['births'].cast('int'))\n",
        "df = df.withColumn('day_of_week', df['day_of_week'].cast('int'))\n",
        "df = df.withColumn('date_of_month', df['date_of_month'].cast('int'))\n",
        "df = df.withColumn('month', df['month'].cast('int'))\n",
        "df = df.withColumn('year', df['year'].cast('int'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "86a93804-96e8-4885-bb5b-c54e419a0916",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "g9LAWv9QfDoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8feb80bd-3193-4e9e-db36-030c09f1f703"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(year=2000, month=1, date_of_month=1, day_of_week=6, births=9083, date_vec=SparseVector(31, {1: 1.0}), day_vec=SparseVector(7, {6: 1.0}))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "ohe = feature.OneHotEncoder(inputCols=['date_of_month',\n",
        "                                                'day_of_week'],\n",
        "                                     outputCols=['date_vec',\n",
        "                                                  'day_vec'],\n",
        "                                     dropLast=True)\n",
        "one_hot_encoded = ohe.fit(df).transform(df)\n",
        "one_hot_encoded.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "62567225-2c4a-4ff3-8b70-a20c0a2b46af",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "z13YcRu2fDor"
      },
      "source": [
        "Note the 'SparseVector' we've created!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "9df01298-60df-45b1-b558-829a14477cbd",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "UZxeuwB4fDor"
      },
      "outputs": [],
      "source": [
        "features = ['year', 'month', 'date_of_month', 'day_of_week']\n",
        "\n",
        "target = 'births'\n",
        "\n",
        "vector = VectorAssembler(inputCols=features, outputCol='features')\n",
        "vectorized_df = vector.transform(one_hot_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "7565c684-3a6c-4e7f-9ac1-0c8544ce6fae",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "Zxr3gFckfDos"
      },
      "source": [
        "The Vector Assembler is often what we want when we're building a model in Spark. [How does the VectorAssembler work?](https://spark.apache.org/docs/2.1.0/ml-features.html#vectorassembler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "b32355db-6351-431b-9bf4-7ceefef823d4",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "8IWLy_ENfDos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb34c62-d7fb-46e7-8c7d-5db1f0f3308f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['year',\n",
              " 'month',\n",
              " 'date_of_month',\n",
              " 'day_of_week',\n",
              " 'births',\n",
              " 'date_vec',\n",
              " 'day_vec',\n",
              " 'features']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "vectorized_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "18M1z8yrfDot"
      },
      "source": [
        "# Train and Predict with Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "5a4278a2-0a2b-4fb2-9fcc-86545c194c1a",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "_PgrUl2AfDou"
      },
      "outputs": [],
      "source": [
        "rf_model = RandomForestRegressor(featuresCol='features',\n",
        "                                 labelCol='births',\n",
        "                                 predictionCol=\"prediction\").fit(vectorized_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "e2a65c25-7be6-43b3-ad0a-a0efec038fac",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "DhahPqD3fDou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9017bcf9-5314-4c90-e2d9-04a8da47a105"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(year=2000, month=1, date_of_month=1, day_of_week=6, births=9083, date_vec=SparseVector(31, {1: 1.0}), day_vec=SparseVector(7, {6: 1.0}), features=DenseVector([2000.0, 1.0, 1.0, 6.0]), prediction=8650.578558676723),\n",
              " Row(year=2000, month=1, date_of_month=2, day_of_week=7, births=8006, date_vec=SparseVector(31, {2: 1.0}), day_vec=SparseVector(7, {}), features=DenseVector([2000.0, 1.0, 2.0, 7.0]), prediction=7633.2213951041385),\n",
              " Row(year=2000, month=1, date_of_month=3, day_of_week=1, births=11363, date_vec=SparseVector(31, {3: 1.0}), day_vec=SparseVector(7, {1: 1.0}), features=DenseVector([2000.0, 1.0, 3.0, 1.0]), prediction=11665.350458922223)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "predictions = rf_model.transform(vectorized_df)#.select(\"births\", \"prediction\")\n",
        "predictions.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "LqBNarjWfDou"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "8f61139f-c7eb-4319-9dea-d62cfce1cb6d",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "LuQuk37KfDov"
      },
      "source": [
        "Let's evaluate our model! [Here](https://spark.apache.org/docs/2.2.0/mllib-evaluation-metrics.html) is a reference for the many metrics available in Spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "30d59b5c-5586-4984-a964-4ff9945aeaf8",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "uu7zD5VZfDov"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "30d59b5c-5586-4984-a964-4ff9945aeaf8",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "8k7pHBNFfDov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6de5991b-f376-4998-b820-14efe744ddd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8936133461802924"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='births')\n",
        "\n",
        "evaluator.evaluate(predictions, {evaluator.metricName:\"r2\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "eb8adf31-10e4-4b94-90bc-b1d9a77407c8",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "buWJpQqkfDov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587a3e1d-a620-417a-e418-d9bd689e5229"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "414.88184369661286"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "evaluator.evaluate(predictions, {evaluator.metricName:\"mae\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "HLf5RE63fDow"
      },
      "source": [
        "# Using Pipeline and Performing a Grid Search for Optimal Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "71e41dd8-9242-45ee-924c-8a34a8efb364",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "TQ-bqfOpfDow"
      },
      "outputs": [],
      "source": [
        "one_hot_encoder = OneHotEncoder(inputCols=['date_of_month',\n",
        "                                                'day_of_week'],\n",
        "                                     outputCols=['date_vec',\n",
        "                                                  'day_vec'],\n",
        "                                     dropLast=True)\n",
        "vector_assember = VectorAssembler(inputCols=features,\n",
        "                                  outputCol='features')\n",
        "random_forest = RandomForestRegressor(featuresCol='features',\n",
        "                                      labelCol='births')\n",
        "stages = [one_hot_encoder, vector_assember, random_forest]\n",
        "\n",
        "pipeline = Pipeline(stages=stages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "7f22a487-ae2a-4c7e-85bc-a15edfdc601d",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "7_q1rgnSfDow"
      },
      "source": [
        "Note: The stages in a pipeline can be either *Transformers* or *Estimators*. An estimator fits a DataFrame to produce a Transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "d3d1c4a4-9534-4292-b0c2-e894568b18fd",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "IhNTAwYcfDow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39aeab82-79f6-4380-8963-3edafeeed709"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Param(parent='RandomForestRegressor_ff68d259823d', name='bootstrap', doc='Whether bootstrap samples are used when building trees.'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='featuresCol', doc='features column name.'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='labelCol', doc='label column name.'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='numTrees', doc='Number of trees to train (>= 1).'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='predictionCol', doc='prediction column name.'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='seed', doc='random seed.'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'),\n",
              " Param(parent='RandomForestRegressor_ff68d259823d', name='weightCol', doc='weight column name. If this is not set or empty, we treat all instance weights as 1.0.')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "random_forest.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "37cb006e-18b0-482a-86e5-e791db4af5ba",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "taFBq1cSfDox"
      },
      "outputs": [],
      "source": [
        "params = ParamGridBuilder().addGrid(random_forest.numTrees, [20, 50, 100]).build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "e5a25b89-173d-4125-aee4-8a669ea2e865",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "CVGTMQIWfDox"
      },
      "outputs": [],
      "source": [
        "reg_evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='births',\n",
        "                                    metricName='mae')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "33QEagWFfDox"
      },
      "source": [
        "## Evaluate with Cross Validation to Find Optimal Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "679011e7-8b9b-4f45-a39a-2b82f8424d6b",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "gCrmI_IVfDox"
      },
      "outputs": [],
      "source": [
        "cv = CrossValidator(\n",
        "    estimator=pipeline,\n",
        "    estimatorParamMaps=params,\n",
        "    evaluator=reg_evaluator,\n",
        "    parallelism=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "cf5035ad-0e62-46f4-b4b9-76bb218eff78",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "Kzs72uXefDoy"
      },
      "outputs": [],
      "source": [
        "cross_validated_model = cv.fit(df.cache())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "c22a7ec3-61ff-452b-9a12-b0ecce619762",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "p73Gzf7CfDoy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf0b8e2-6acb-409c-d1c7-cfd76ed1494c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[426.64467616212795, 440.1537071420042, 430.421358603493]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "cross_validated_model.avgMetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "40d18fda-9c91-41a5-bd2d-853e2032d9dd",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "POPXZMrefDo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d525ce5c-a9ef-4c65-8a49-70827bb11f7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PipelineModel_516e38892abc"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "cross_validated_model.bestModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "8c616ba9-a273-42ab-abd0-edd80ea2fbbb",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "z--ujDk2fDo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5967f2e5-c366-4013-d872-373ec28224f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[OneHotEncoderModel: uid=OneHotEncoder_7faabde8ec06, dropLast=true, handleInvalid=error, numInputCols=2, numOutputCols=2,\n",
              " VectorAssembler_05bf06c6c86a,\n",
              " RandomForestRegressionModel: uid=RandomForestRegressor_ff68d259823d, numTrees=20, numFeatures=4]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "cross_validated_model.bestModel.stages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "1517c851-5965-4f26-a229-d0e7df3dc894",
          "showTitle": false,
          "title": ""
        },
        "hidden": true,
        "id": "NU_aweSGfDo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e56dd70d-1e78-4fce-84c6-329a9e22696b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "cross_validated_model.bestModel.stages[2].getNumTrees"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nf_E3XxmjA82"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}